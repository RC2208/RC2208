{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.Diabetes_Prediction_DL Lab-3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X28K-hIE9qU"
      },
      "source": [
        "Ritika Chand <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIvwj4B1roj9"
      },
      "source": [
        "#multilayrer ANN(DNN)\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential #each layer in sequence\n",
        "from keras.layers import Dense #specify parameters of each layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m2AeZG4rxEK",
        "outputId": "0ead68a1-deb3-43b9-aab9-678a57183269"
      },
      "source": [
        "dataset=loadtxt('pima-indians-diabetes.csv',delimiter=',') #seperator in csv is comma{,} specify new row is ','\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l07mBUkrxGZ",
        "outputId": "37620a0a-24a8-4703-dfa0-a5920e45ad8c"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b40KARLErxJp",
        "outputId": "945bd973-efdb-40af-fe09-466f32191ca4"
      },
      "source": [
        "dataset[0,:] \n",
        "#1st column=surgery no. of times\n",
        "#2nd=glucose conc. percentage\n",
        "#3rd blood pressure\n",
        "#4th thickness of skinfold\n",
        "#5th syrum:insulin\n",
        "#6th body mass index\n",
        "#7th dibatese pedigree function\n",
        "#8th age\n",
        "#9th column: outcome...diabtese or not"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  6.   , 148.   ,  72.   ,  35.   ,   0.   ,  33.6  ,   0.627,\n",
              "        50.   ,   1.   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsNXUX13rxLL"
      },
      "source": [
        "x=dataset[:,0:8] #input\n",
        "y=dataset[:,8] #output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7x7q5Q_rxPA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.2,random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnbSx_rZrxQj"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(14,input_dim=8,activation='relu')) #adding layer. Giving 8 features as we hv 8 columns.\n",
        "#14 neurons in hidden layer\n",
        "model.add(Dense(9,activation='relu')) \n",
        "\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid')) #output layer thus only 1 neuron\n",
        "#we need output as 0 or 1 thus we don't use relu."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw_bNoLZrxUe"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=(['accuracy']))\n",
        "#binary_crossentropy=p*log(q), q=predicted probabality;p=actual prob\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N72-F8SrxWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1903fa-b9c9-424d-c82c-61ebff4d9ffb"
      },
      "source": [
        "model.fit(train_x,train_y,epochs=180,batch_size=15) #150 times it occurs\n",
        "#takes 10 samples one by one, calculate loss and adds losses, updates weight and then take next set of samples\n",
        "#all samples exhausted=1 epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 4.8105 - accuracy: 0.5791\n",
            "Epoch 2/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 2.3667 - accuracy: 0.6435\n",
            "Epoch 3/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 1.5936 - accuracy: 0.6509\n",
            "Epoch 4/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5572\n",
            "Epoch 5/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.9505 - accuracy: 0.4771\n",
            "Epoch 6/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.7717 - accuracy: 0.5991\n",
            "Epoch 7/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.7838 - accuracy: 0.6101\n",
            "Epoch 8/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.5809\n",
            "Epoch 9/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6659\n",
            "Epoch 10/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6495\n",
            "Epoch 11/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6787\n",
            "Epoch 12/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6344\n",
            "Epoch 13/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6708\n",
            "Epoch 14/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6716\n",
            "Epoch 15/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6932\n",
            "Epoch 16/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6904\n",
            "Epoch 17/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6299\n",
            "Epoch 18/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6147 - accuracy: 0.6798\n",
            "Epoch 19/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6602\n",
            "Epoch 20/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6920\n",
            "Epoch 21/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.6847\n",
            "Epoch 22/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.7032\n",
            "Epoch 23/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6711\n",
            "Epoch 24/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6829\n",
            "Epoch 25/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6834\n",
            "Epoch 26/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6504\n",
            "Epoch 27/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6852\n",
            "Epoch 28/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7366\n",
            "Epoch 29/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6792\n",
            "Epoch 30/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7223\n",
            "Epoch 31/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7028\n",
            "Epoch 32/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6811\n",
            "Epoch 33/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7047\n",
            "Epoch 34/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7320\n",
            "Epoch 35/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.6873\n",
            "Epoch 36/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7316\n",
            "Epoch 37/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6940\n",
            "Epoch 38/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7241\n",
            "Epoch 39/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7020\n",
            "Epoch 40/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.7068\n",
            "Epoch 41/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7028\n",
            "Epoch 42/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7590\n",
            "Epoch 43/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6805\n",
            "Epoch 44/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.6920\n",
            "Epoch 45/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7215\n",
            "Epoch 46/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7320\n",
            "Epoch 47/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7068\n",
            "Epoch 48/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.6947\n",
            "Epoch 49/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.6693\n",
            "Epoch 50/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7043\n",
            "Epoch 51/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7100\n",
            "Epoch 52/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7034\n",
            "Epoch 53/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7259\n",
            "Epoch 54/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7078\n",
            "Epoch 55/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7120\n",
            "Epoch 56/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7165\n",
            "Epoch 57/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7335\n",
            "Epoch 58/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7124\n",
            "Epoch 59/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7017\n",
            "Epoch 60/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7277\n",
            "Epoch 61/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7351\n",
            "Epoch 62/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7233\n",
            "Epoch 63/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7222\n",
            "Epoch 64/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6845\n",
            "Epoch 65/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7255\n",
            "Epoch 66/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7220\n",
            "Epoch 67/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7249\n",
            "Epoch 68/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7400\n",
            "Epoch 69/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7370\n",
            "Epoch 70/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6889\n",
            "Epoch 71/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6898\n",
            "Epoch 72/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7267\n",
            "Epoch 73/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7200\n",
            "Epoch 74/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7063\n",
            "Epoch 75/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7299\n",
            "Epoch 76/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6988\n",
            "Epoch 77/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7201\n",
            "Epoch 78/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7483\n",
            "Epoch 79/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.7410\n",
            "Epoch 80/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7317\n",
            "Epoch 81/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7462\n",
            "Epoch 82/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7048\n",
            "Epoch 83/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.7148\n",
            "Epoch 84/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7272\n",
            "Epoch 85/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7011\n",
            "Epoch 86/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7634\n",
            "Epoch 87/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7258\n",
            "Epoch 88/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7270\n",
            "Epoch 89/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6772\n",
            "Epoch 90/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7526\n",
            "Epoch 91/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7287\n",
            "Epoch 92/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7008\n",
            "Epoch 93/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7298\n",
            "Epoch 94/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7304\n",
            "Epoch 95/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7376\n",
            "Epoch 96/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7326\n",
            "Epoch 97/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6903\n",
            "Epoch 98/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7080\n",
            "Epoch 99/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7117\n",
            "Epoch 100/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7265\n",
            "Epoch 101/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7286\n",
            "Epoch 102/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7258\n",
            "Epoch 103/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6850\n",
            "Epoch 104/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7086\n",
            "Epoch 105/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7304\n",
            "Epoch 106/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7223\n",
            "Epoch 107/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7241\n",
            "Epoch 108/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7068\n",
            "Epoch 109/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.6928\n",
            "Epoch 110/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7171\n",
            "Epoch 111/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7513\n",
            "Epoch 112/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.6868\n",
            "Epoch 113/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6934\n",
            "Epoch 114/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7258\n",
            "Epoch 115/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7424\n",
            "Epoch 116/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7340\n",
            "Epoch 117/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7597\n",
            "Epoch 118/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7236\n",
            "Epoch 119/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7470\n",
            "Epoch 120/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7288\n",
            "Epoch 121/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7377\n",
            "Epoch 122/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.7000\n",
            "Epoch 123/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7685\n",
            "Epoch 124/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7372\n",
            "Epoch 125/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7311\n",
            "Epoch 126/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7192\n",
            "Epoch 127/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7370\n",
            "Epoch 128/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7313\n",
            "Epoch 129/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7147\n",
            "Epoch 130/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7429\n",
            "Epoch 131/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7020\n",
            "Epoch 132/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7439\n",
            "Epoch 133/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7385\n",
            "Epoch 134/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7601\n",
            "Epoch 135/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7147\n",
            "Epoch 136/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7282\n",
            "Epoch 137/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7494\n",
            "Epoch 138/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7700\n",
            "Epoch 139/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7550\n",
            "Epoch 140/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7300\n",
            "Epoch 141/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7614\n",
            "Epoch 142/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7348\n",
            "Epoch 143/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7233\n",
            "Epoch 144/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7421\n",
            "Epoch 145/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7554\n",
            "Epoch 146/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7456\n",
            "Epoch 147/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7314\n",
            "Epoch 148/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7522\n",
            "Epoch 149/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7536\n",
            "Epoch 150/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7397\n",
            "Epoch 151/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7456\n",
            "Epoch 152/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7430\n",
            "Epoch 153/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7624\n",
            "Epoch 154/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7166\n",
            "Epoch 155/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7336\n",
            "Epoch 156/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7262\n",
            "Epoch 157/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7348\n",
            "Epoch 158/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7619\n",
            "Epoch 159/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7393\n",
            "Epoch 160/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7608\n",
            "Epoch 161/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7596\n",
            "Epoch 162/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7304\n",
            "Epoch 163/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7617\n",
            "Epoch 164/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7677\n",
            "Epoch 165/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7545\n",
            "Epoch 166/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7569\n",
            "Epoch 167/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.6991\n",
            "Epoch 168/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.7361\n",
            "Epoch 169/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7253\n",
            "Epoch 170/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7280\n",
            "Epoch 171/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7288\n",
            "Epoch 172/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7215\n",
            "Epoch 173/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7277\n",
            "Epoch 174/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7178\n",
            "Epoch 175/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7357\n",
            "Epoch 176/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7268\n",
            "Epoch 177/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7304\n",
            "Epoch 178/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7491\n",
            "Epoch 179/180\n",
            "41/41 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7335\n",
            "Epoch 180/180\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f40548d0710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7YY15z1rxZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61017138-a9c1-46a7-8a46-ff1dba574288"
      },
      "source": [
        "training_accuracy=model.evaluate(train_x,train_y)\n",
        "print(\"%s: %.2f%%\"% (model.metrics_names[1],training_accuracy[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7313\n",
            "accuracy: 73.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61UlBBCrxbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742c4ada-e1a9-4283-979d-8b4b0484c6a2"
      },
      "source": [
        "training_loss=model.evaluate(train_x,train_y)\n",
        "print(\"%s: %.2f%%\"% (model.metrics_names[0],training_loss[0]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7313\n",
            "loss: 52.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjXTSIS3rxfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa0976e-5e45-4439-8820-51222d253c86"
      },
      "source": [
        "testing_accuracy=model.evaluate(test_x,test_y)\n",
        "print(\"%s: %.2f%%\"% (model.metrics_names[1],testing_accuracy[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7727\n",
            "accuracy: 77.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-teHihjrxhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825bba51-439a-4578-81f8-50bb4701780b"
      },
      "source": [
        "predict=model.predict_classes(test_x)\n",
        "for i in range(10):\n",
        "  print(\"%s=>  %d (actual %d)\"% (test_x[i].tolist(),predict[i],test_y[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 100.0, 66.0, 29.0, 196.0, 32.0, 0.444, 42.0]=>  0 (actual 0)\n",
            "[9.0, 57.0, 80.0, 37.0, 0.0, 32.8, 0.096, 41.0]=>  0 (actual 0)\n",
            "[0.0, 100.0, 70.0, 26.0, 50.0, 30.8, 0.597, 21.0]=>  0 (actual 0)\n",
            "[1.0, 119.0, 88.0, 41.0, 170.0, 45.3, 0.507, 26.0]=>  0 (actual 0)\n",
            "[2.0, 102.0, 86.0, 36.0, 120.0, 45.5, 0.127, 23.0]=>  0 (actual 1)\n",
            "[13.0, 126.0, 90.0, 0.0, 0.0, 43.4, 0.583, 42.0]=>  1 (actual 1)\n",
            "[3.0, 171.0, 72.0, 33.0, 135.0, 33.3, 0.199, 24.0]=>  0 (actual 1)\n",
            "[12.0, 92.0, 62.0, 7.0, 258.0, 27.6, 0.926, 44.0]=>  0 (actual 1)\n",
            "[12.0, 151.0, 70.0, 40.0, 271.0, 41.8, 0.742, 38.0]=>  1 (actual 1)\n",
            "[11.0, 85.0, 74.0, 0.0, 0.0, 30.1, 0.3, 35.0]=>  0 (actual 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87lGHhoorxkj"
      },
      "source": [
        "#if training accuracy is good but testing is bad then model is biased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2BL89n-rxm9"
      },
      "source": [
        "#conclusion: Deep neural network with 2 hidden layers is constructed for\n",
        "# the data set to classify wether patient has dibetes or not.\n",
        "#optimizer is adam which is an advanced form of gradient decent algo.\n",
        "#instead of mean squeare error, binary_cross_entropy is used as a loss function\n",
        "# this is used as binary cross entropy converges the network faster and gives better accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96RZwoc6GYf3"
      },
      "source": [
        "trained network has almost equal amount of training and testing accuracy. Thus it can be concluded that the network has reasonable amount of bias and varience.<br>\n",
        "\n",
        "I have changed the number of neurons in hidden layers and the opchs as well as batch size. The accuracy decreased with the changes"
      ]
    }
  ]
}